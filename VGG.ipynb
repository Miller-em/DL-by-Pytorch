{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 使用块的网络 VGG"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "'''\n",
    "首先定义VGG块\n",
    "'''\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "\tlayers = []\n",
    "\tfor _ in range(num_convs):\n",
    "\t\tlayers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "\t\tlayers.append(nn.ReLU())\n",
    "\t\tin_channels = out_channels\n",
    "\tlayers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\treturn nn.Sequential(*layers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'''\n",
    "原始 VGG 网络有 5 个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。 \n",
    "第一个模块有 64 个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到 512。\n",
    "由于该网络使用 8 个卷积层和 3 个全连接层，因此它通常被称为 VGG-11。\n",
    "'''\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "'''\n",
    "构建VGG-11\n",
    "'''\n",
    "def vgg(conv_arch):\n",
    "\tconv_blks = []\n",
    "\tin_channels = 1\n",
    "\t# 卷积层部分\n",
    "\tfor (num_convs, out_channels) in conv_arch:\n",
    "\t\tconv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "\t\tin_channels = out_channels\n",
    "\treturn nn.Sequential(\n",
    "\t\t*conv_blks,\n",
    "\t\tnn.Flatten(),\n",
    "\t\tnn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10)\n",
    "\t)\n",
    "\n",
    "net = vgg(conv_arch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 观察输出\n",
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/xiaozhoua/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "7153f77ce21c9bde3e937cf13a746a7287849b9694dfad9873ee7b31426be34b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}